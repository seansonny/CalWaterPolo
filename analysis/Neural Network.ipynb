{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wyh/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-50b9423d63a2>:72: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Step 1, Minibatch Loss= 19.7219, Training Accuracy= 0.255\n",
      "Step 100, Minibatch Loss= 4.9014, Training Accuracy= 0.627\n",
      "Step 200, Minibatch Loss= 0.6740, Training Accuracy= 0.784\n",
      "Step 300, Minibatch Loss= 0.3245, Training Accuracy= 0.892\n",
      "Step 400, Minibatch Loss= 0.2221, Training Accuracy= 0.931\n",
      "Step 500, Minibatch Loss= 0.1705, Training Accuracy= 0.951\n",
      "Step 600, Minibatch Loss= 0.1425, Training Accuracy= 0.961\n",
      "Step 700, Minibatch Loss= 0.1258, Training Accuracy= 0.971\n",
      "Step 800, Minibatch Loss= 0.1133, Training Accuracy= 0.971\n",
      "Step 900, Minibatch Loss= 0.1033, Training Accuracy= 0.971\n",
      "Step 1000, Minibatch Loss= 0.0949, Training Accuracy= 0.971\n",
      "Step 1100, Minibatch Loss= 0.0878, Training Accuracy= 0.971\n",
      "Step 1200, Minibatch Loss= 0.0816, Training Accuracy= 0.980\n",
      "Step 1300, Minibatch Loss= 0.0761, Training Accuracy= 0.980\n",
      "Step 1400, Minibatch Loss= 0.0713, Training Accuracy= 0.980\n",
      "Step 1500, Minibatch Loss= 0.0668, Training Accuracy= 0.980\n",
      "Step 1600, Minibatch Loss= 0.0628, Training Accuracy= 0.980\n",
      "Step 1700, Minibatch Loss= 0.0590, Training Accuracy= 0.980\n",
      "Step 1800, Minibatch Loss= 0.0556, Training Accuracy= 0.980\n",
      "Step 1900, Minibatch Loss= 0.0523, Training Accuracy= 0.990\n",
      "Step 2000, Minibatch Loss= 0.0493, Training Accuracy= 0.990\n",
      "Step 2100, Minibatch Loss= 0.0464, Training Accuracy= 0.990\n",
      "Step 2200, Minibatch Loss= 0.0437, Training Accuracy= 0.990\n",
      "Step 2300, Minibatch Loss= 0.0412, Training Accuracy= 0.990\n",
      "Step 2400, Minibatch Loss= 0.0387, Training Accuracy= 0.990\n",
      "Step 2500, Minibatch Loss= 0.0364, Training Accuracy= 0.990\n",
      "Step 2600, Minibatch Loss= 0.0341, Training Accuracy= 0.990\n",
      "Step 2700, Minibatch Loss= 0.0319, Training Accuracy= 0.990\n",
      "Step 2800, Minibatch Loss= 0.0299, Training Accuracy= 0.990\n",
      "Step 2900, Minibatch Loss= 0.0279, Training Accuracy= 0.990\n",
      "Step 3000, Minibatch Loss= 0.0259, Training Accuracy= 1.000\n",
      "Step 3100, Minibatch Loss= 0.0241, Training Accuracy= 1.000\n",
      "Step 3200, Minibatch Loss= 0.0224, Training Accuracy= 1.000\n",
      "Step 3300, Minibatch Loss= 0.0207, Training Accuracy= 1.000\n",
      "Step 3400, Minibatch Loss= 0.0191, Training Accuracy= 1.000\n",
      "Step 3500, Minibatch Loss= 0.0177, Training Accuracy= 1.000\n",
      "Step 3600, Minibatch Loss= 0.0163, Training Accuracy= 1.000\n",
      "Step 3700, Minibatch Loss= 0.0150, Training Accuracy= 1.000\n",
      "Step 3800, Minibatch Loss= 0.0138, Training Accuracy= 1.000\n",
      "Step 3900, Minibatch Loss= 0.0126, Training Accuracy= 1.000\n",
      "Step 4000, Minibatch Loss= 0.0116, Training Accuracy= 1.000\n",
      "Step 4100, Minibatch Loss= 0.0106, Training Accuracy= 1.000\n",
      "Step 4200, Minibatch Loss= 0.0097, Training Accuracy= 1.000\n",
      "Step 4300, Minibatch Loss= 0.0089, Training Accuracy= 1.000\n",
      "Step 4400, Minibatch Loss= 0.0082, Training Accuracy= 1.000\n",
      "Step 4500, Minibatch Loss= 0.0075, Training Accuracy= 1.000\n",
      "Step 4600, Minibatch Loss= 0.0069, Training Accuracy= 1.000\n",
      "Step 4700, Minibatch Loss= 0.0063, Training Accuracy= 1.000\n",
      "Step 4800, Minibatch Loss= 0.0058, Training Accuracy= 1.000\n",
      "Step 4900, Minibatch Loss= 0.0053, Training Accuracy= 1.000\n",
      "Step 5000, Minibatch Loss= 0.0048, Training Accuracy= 1.000\n",
      "Step 5100, Minibatch Loss= 0.0044, Training Accuracy= 1.000\n",
      "Step 5200, Minibatch Loss= 0.0041, Training Accuracy= 1.000\n",
      "Step 5300, Minibatch Loss= 0.0037, Training Accuracy= 1.000\n",
      "Step 5400, Minibatch Loss= 0.0034, Training Accuracy= 1.000\n",
      "Step 5500, Minibatch Loss= 0.0032, Training Accuracy= 1.000\n",
      "Step 5600, Minibatch Loss= 0.0029, Training Accuracy= 1.000\n",
      "Step 5700, Minibatch Loss= 0.0027, Training Accuracy= 1.000\n",
      "Step 5800, Minibatch Loss= 0.0025, Training Accuracy= 1.000\n",
      "Step 5900, Minibatch Loss= 0.0023, Training Accuracy= 1.000\n",
      "Step 6000, Minibatch Loss= 0.0021, Training Accuracy= 1.000\n",
      "Step 6100, Minibatch Loss= 0.0019, Training Accuracy= 1.000\n",
      "Step 6200, Minibatch Loss= 0.0018, Training Accuracy= 1.000\n",
      "Step 6300, Minibatch Loss= 0.0016, Training Accuracy= 1.000\n",
      "Step 6400, Minibatch Loss= 0.0015, Training Accuracy= 1.000\n",
      "Step 6500, Minibatch Loss= 0.0014, Training Accuracy= 1.000\n",
      "Step 6600, Minibatch Loss= 0.0013, Training Accuracy= 1.000\n",
      "Step 6700, Minibatch Loss= 0.0012, Training Accuracy= 1.000\n",
      "Step 6800, Minibatch Loss= 0.0011, Training Accuracy= 1.000\n",
      "Step 6900, Minibatch Loss= 0.0010, Training Accuracy= 1.000\n",
      "Step 7000, Minibatch Loss= 0.0009, Training Accuracy= 1.000\n",
      "Step 7100, Minibatch Loss= 0.0009, Training Accuracy= 1.000\n",
      "Step 7200, Minibatch Loss= 0.0008, Training Accuracy= 1.000\n",
      "Step 7300, Minibatch Loss= 0.0008, Training Accuracy= 1.000\n",
      "Step 7400, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Step 7500, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Step 7600, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Step 7700, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Step 7800, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Step 7900, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Step 8000, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Step 8100, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Step 8200, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Step 8300, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Step 8400, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Step 8500, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Step 8600, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Step 8700, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Step 8800, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Step 8900, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Step 9000, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Step 9100, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Step 9200, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Step 9300, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Step 9400, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Step 9500, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Step 9600, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Step 9700, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Step 9800, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Step 9900, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Step 10000, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Step 10100, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Step 10200, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Step 10300, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Step 10400, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Step 10500, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Step 10600, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Step 10700, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Step 10800, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Step 10900, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Step 11000, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Step 11100, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Step 11200, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Step 11300, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Step 11400, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 11500, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 11600, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 11700, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 11800, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 11900, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 12000, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 12100, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 12200, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 12300, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 12400, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 12500, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 12600, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 12700, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 12800, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 12900, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 13000, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 13100, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 13200, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 13300, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 13400, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 13500, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 13600, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 13700, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 13800, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 13900, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 14000, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 14100, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 14200, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 14300, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 14400, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 14500, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 14600, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 14700, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 14800, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 14900, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 15000, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 15100, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 15200, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 15300, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 15400, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 15500, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 15600, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 15700, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 15800, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 15900, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 16000, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 16100, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 16200, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 16300, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 16400, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 16500, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 16600, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 16700, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 16800, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 16900, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 17000, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 17100, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 17200, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 17300, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 17400, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 17500, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 17600, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 17700, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 17800, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 17900, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 18000, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 18100, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 18200, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 18300, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 18400, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 18500, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 18600, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 18700, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 18800, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 18900, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 19000, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 19100, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 19200, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 19300, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 19400, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 19500, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 19600, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 19700, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 19800, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 19900, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 20000, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7241379\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Neural Network.\n",
    "A 2-Hidden Layers Fully Connected Neural Network (a.k.a Multilayer Perceptron)\n",
    "implementation with TensorFlow. This example is using the MNIST database\n",
    "of handwritten digits (http://yann.lecun.com/exdb/mnist/).\n",
    "Links:\n",
    "    [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\n",
    "Author: Aymeric Damien\n",
    "Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# read data\n",
    "data = pandas.read_csv('dir_change.csv')\n",
    "X = data.iloc[:, 2:171]\n",
    "Y = data.iloc[:, 1]\n",
    "x_train, x_test0, y_train, y_test0 = train_test_split(X, Y, test_size=0.3, random_state=100)\n",
    "x_test, x_validation, y_test, y_validation = train_test_split(x_test0, y_test0, test_size=0.333, random_state=100)\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "num_steps = 20000\n",
    "batch_size = 32\n",
    "display_step = 100\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 64 # 1st layer number of neurons\n",
    "n_hidden_2 = 10 # 2nd layer number of neurons\n",
    "# n_hidden_3 = 512 # 3rd layer number of neurons\n",
    "num_input = 169 \n",
    "num_classes = 3 # 类别为4(0, 1, 2)\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([num_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "#     'h3': tf.Variable(tf.random_normal([n_hidden_2, n_hidden_3])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "#     'b3': tf.Variable(tf.random_normal([n_hidden_3])),\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n",
    "\n",
    "\n",
    "# Create model\n",
    "def neural_net(x):\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    # Output fully connected layer with a neuron for each class\n",
    "#     layer_3 = tf.add(tf.matmul(layer_2, weights['h3']), biases['b3'])\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer\n",
    "\n",
    "# Construct model\n",
    "logits = neural_net(X)\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Start training\n",
    "stepnum = []\n",
    "minibatch_loss = []\n",
    "training_accuracy = []\n",
    "validation_accuracy = []\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    for step in range(1, num_steps+1):\n",
    "        #batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        # Run optimization op (backprop)\n",
    "        # 随机抽样 batch_size个样本\n",
    "        data_batch = data.sample(batch_size)\n",
    "\n",
    "        # 抽取特征(1维,长度为4)和标签(1维, 长度为1)\n",
    "        features = x_train.values # 特征为csv中的第2到第5列 shape = (128, 4)\n",
    "        labels = y_train.values # 特征为csv中的第6列 shape = (128,1)\n",
    "        # 此时 features与labels均为numpy数组\n",
    "        # batch_x 即当前批次的特征\n",
    "        batch_x = features\n",
    "        # batch_y 需要将label进行one_hot转换\n",
    "        batch_y = np.eye(labels.shape[0])[labels][:,0:num_classes]\n",
    "        \n",
    "        # validation\n",
    "        val_features = x_validation.values\n",
    "        val_labels = y_validation.values\n",
    "        val_x = val_features\n",
    "        val_y = np.eye(val_labels.shape[0])[val_labels][:,0:num_classes]\n",
    "        \n",
    "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
    "        if step % display_step == 0 or step == 1:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n",
    "                                                                 Y: batch_y})\n",
    "            val_acc = sess.run(accuracy, feed_dict={X: val_x, Y: val_y})\n",
    "            stepnum.append(step)\n",
    "            minibatch_loss.append(loss)\n",
    "            training_accuracy.append(acc)\n",
    "            validation_accuracy.append(val_acc)\n",
    "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.3f}\".format(acc))\n",
    "            \n",
    "    test_data = x_test.values\n",
    "    test_labels = y_test.values\n",
    "    batch_x = test_data\n",
    "    batch_y = np.eye(test_labels.shape[0])[test_labels][:,0:num_classes]\n",
    "    print(\"Optimization Finished!\")\n",
    "    print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict={X: batch_x, Y: batch_y}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a4942ce48>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2,ncols=1,figsize=(15,10))\n",
    "\n",
    "# ax[0].set_xlim((0, 100000)\n",
    "# ax[0].set_ylim((0, 1))\n",
    "\n",
    "# ax[1].set_xlim((0, 100000))\n",
    "# ax[1].set_ylim((0, max(minibatch_loss)))\n",
    "\n",
    "ax[0].set_title('Minibatch Loss')\n",
    "ax[1].set_title('Training Accuracy')\n",
    "\n",
    "line1, = ax[0].plot([], [], lw=2)\n",
    "line2, = ax[1].plot([], [], lw=2)\n",
    "               \n",
    "ax[0].plot(stepnum, minibatch_loss)\n",
    "ax[1].plot(stepnum, training_accuracy)\n",
    "ax[1].plot(stepnum, validation_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence Generation\n",
    "net = tflearn.input_data(shape=[None, 100, 5000])\n",
    "net = tflearn.lstm(net, 64)\n",
    "net = tflearn.dropout(net, 0.5)\n",
    "net = tflearn.fully_connected(net, 5000, activation='softmax')\n",
    "net = tflearn.regression(net, optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "model = tflearn.SequenceGenerator(net, dictionary=idx, seq_maxlen=100)\n",
    "model.fit(X, Y)\n",
    "model.generate(50, temperature=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf learn\n",
    "# validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tflearn\n",
    "tflearn.init_graph(num_cores=8, gpu_memory_fraction=0.5)\n",
    "\n",
    "net = tflearn.input_data(shape=[None, 171])\n",
    "net = tflearn.fully_connected(net, 64)\n",
    "net = tflearn.dropout(net, 0.5)\n",
    "net = tflearn.fully_connected(net, 3, activation='softmax')\n",
    "net = tflearn.regression(net, optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "model = tflearn.DNN(net)\n",
    "model.fit(X, Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
